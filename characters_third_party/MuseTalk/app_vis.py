import os
import sys
import time
import json
import queue
import threading
import subprocess
import uuid
import cv2
import torch
import whisper
from datetime import datetime
from typing import Tuple

# -------------------------- 1. å…¨å±€é…ç½®ï¼ˆè¯·æ ¹æ®ä½ çš„ç¯å¢ƒä¿®æ”¹ï¼‰ --------------------------
CONFIG = {
    "VIDEO_PATH": "original.mp4",          # ä½ çš„åŸè§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    "WAV_MONITOR_DIR": "./wav_inputs",     # ç›‘æ§WAVæ–‡ä»¶çš„æ–‡ä»¶å¤¹ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    "OUTPUT_FRAME_DIR": "./output_frames", # ç”Ÿæˆå¸§çš„è¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    "PROCESSING_TMP_DIR": "./processing",  # å¤„ç†ä¸­WAVçš„ä¸´æ—¶ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    "LOG_FILE": "processing_log.json",     # å¤„ç†æ—¥å¿—æ–‡ä»¶
    "MUSETALK_VAE_PATH": "ft-mse-vae.pt",  # MuseTalkçš„VAEæƒé‡è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    "MUSETALK_UNET_PATH": "musetalk_unet.pt", # MuseTalkçš„UNetæƒé‡è·¯å¾„ï¼ˆå¿…å¡«ï¼‰
    "DELAY_SEC": 0.3,                      # éŸ³ç”»åŒæ­¥å»¶è¿Ÿï¼ˆé»˜è®¤0.3ç§’ï¼Œå¯å¾®è°ƒï¼‰
    "NUM_WORKERS": max(1, os.cpu_count() // 2) # å¤„ç†çº¿ç¨‹æ•°ï¼ˆé»˜è®¤CPUæ ¸å¿ƒæ•°çš„ä¸€åŠï¼‰
}

# -------------------------- 2. å·¥å…·å‡½æ•° --------------------------
def init_dirs() -> None:
    """åˆå§‹åŒ–æ‰€æœ‰å¿…è¦ç›®å½•"""
    for dir_path in [
        CONFIG["WAV_MONITOR_DIR"],
        CONFIG["OUTPUT_FRAME_DIR"],
        CONFIG["PROCESSING_TMP_DIR"]
    ]:
        os.makedirs(dir_path, exist_ok=True)
    print(f"âœ… ç›®å½•åˆå§‹åŒ–å®Œæˆï¼š\n- WAVç›‘æ§ï¼š{CONFIG['WAV_MONITOR_DIR']}\n- è¾“å‡ºå¸§ï¼š{CONFIG['OUTPUT_FRAME_DIR']}\n- ä¸´æ—¶å¤„ç†ï¼š{CONFIG['PROCESSING_TMP_DIR']}")

def load_processing_log() -> dict:
    """åŠ è½½å¤„ç†æ—¥å¿—ï¼ˆé¿å…é‡å¤å¤„ç†å·²å®Œæˆçš„WAVï¼‰"""
    if os.path.exists(CONFIG["LOG_FILE"]):
        try:
            with open(CONFIG["LOG_FILE"], "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"âš ï¸  æ—¥å¿—åŠ è½½å¤±è´¥ï¼Œé‡æ–°åˆ›å»ºï¼š{str(e)}")
    return {}

def save_processing_log(log: dict) -> None:
    """ä¿å­˜å¤„ç†æ—¥å¿—"""
    try:
        with open(CONFIG["LOG_FILE"], "w", encoding="utf-8") as f:
            json.dump(log, f, indent=2)
    except Exception as e:
        print(f"âš ï¸  æ—¥å¿—ä¿å­˜å¤±è´¥ï¼š{str(e)}")

def check_file_ready(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å®Œå…¨å†™å…¥ï¼ˆé¿å…è¯»å–æœªä¸Šä¼ å®Œçš„WAVï¼‰"""
    try:
        with open(file_path, "rb") as f:
            f.seek(-1, os.SEEK_END)  # å°è¯•è¯»å–æ–‡ä»¶æœ€åä¸€ä¸ªå­—èŠ‚
        return True
    except Exception:
        return False

# -------------------------- 3. MuseTalkæ ¸å¿ƒå¤„ç†æ¨¡å— --------------------------
class MuseTalkProcessor:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ğŸ”§ åˆå§‹åŒ–æ¨¡å‹ï¼ˆè®¾å¤‡ï¼š{self.device}ï¼‰...")
        self.musetalk = self._load_musetalk()
        self.whisper_model = whisper.load_model("tiny", device=self.device)
        print("âœ… æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

    def _load_musetalk(self):
        """åŠ è½½MuseTalkæ¨¡å‹ï¼ˆéœ€æå‰ä¸‹è½½æƒé‡ï¼‰"""
        try:
            from muse_talk import MuseTalk  # å¯¼å…¥MuseTalkï¼ˆéœ€æå‰å®‰è£…ï¼‰
            return MuseTalk(
                vae_path=CONFIG["MUSETALK_VAE_PATH"],
                unet_path=CONFIG["MUSETALK_UNET_PATH"],
                device=self.device
            )
        except ImportError:
            print("âŒ æœªå®‰è£…muse-talkï¼Œè¯·å…ˆæ‰§è¡Œï¼špip install muse-talk")
            sys.exit(1)
        except FileNotFoundError:
            print(f"âŒ MuseTalkæƒé‡æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š\n- VAE: {CONFIG['MUSETALK_VAE_PATH']}\n- UNET: {CONFIG['MUSETALK_UNET_PATH']}")
            sys.exit(1)

    def extract_audio_features(self, audio_path: str) -> torch.Tensor:
        """æå–éŸ³é¢‘çš„Melé¢‘è°±ç‰¹å¾ï¼ˆä¾›MuseTalkä½¿ç”¨ï¼‰"""
        audio = whisper.load_audio(audio_path)
        audio = whisper.pad_or_trim(audio)  # ç»Ÿä¸€éŸ³é¢‘é•¿åº¦
        return whisper.log_mel_spectrogram(audio).to(self.device)

    def process_video_frame(self, video_path: str, audio_path: str, output_dir: str) -> None:
        """å¤„ç†è§†é¢‘ï¼Œç”Ÿæˆå˜´å½¢åŒæ­¥çš„å¸§"""
        # 1. æå–éŸ³é¢‘ç‰¹å¾
        mel = self.extract_audio_features(audio_path)
        
        # 2. æ‰“å¼€åŸè§†é¢‘
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"âŒ æ— æ³•æ‰“å¼€åŸè§†é¢‘ï¼š{video_path}")
        fps = cap.get(cv2.CAP_PROP_FPS)
        delay_frames = max(1, int(CONFIG["DELAY_SEC"] * fps))  # å»¶è¿Ÿå¸§æ•°ï¼ˆå¯¹é½éŸ³ç”»ï¼‰
        
        # 3. é€å¸§å¤„ç†
        frame_idx = 0
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break  # è§†é¢‘å¤„ç†å®Œæ¯•
            
            # è¾“å‡ºå¸§è·¯å¾„ï¼ˆæŒ‰ç´¢å¼•å‘½åï¼Œä¾¿äºå‰ç«¯æŒ‰é¡ºåºè¯»å–ï¼‰
            frame_save_path = os.path.join(output_dir, f"frame_{frame_idx:06d}.jpg")
            
            # å‰Nå¸§è¾“å‡ºåŸè§†é¢‘ï¼ˆå»¶è¿Ÿå¯¹é½ï¼‰
            if frame_idx < delay_frames:
                cv2.imwrite(frame_save_path, frame)
                frame_idx += 1
                continue
            
            # MuseTalkç”Ÿæˆå˜´å½¢åŒæ­¥å¸§
            try:
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # è½¬æ¢ä¸ºRGBæ ¼å¼
                generated_frame = self.musetalk.generate(
                    source_frame=rgb_frame,
                    ref_frame=rgb_frame,  # ç”¨å½“å‰å¸§åšå‚è€ƒï¼ˆä¿æŒèº«ä»½ä¸€è‡´ï¼‰
                    audio_mel=mel,
                    frame_idx=frame_idx - delay_frames  # å¯¹é½éŸ³é¢‘æ—¶é—´
                )
                # è½¬æ¢å›BGRæ ¼å¼å¹¶ä¿å­˜
                cv2.imwrite(frame_save_path, cv2.cvtColor(generated_frame, cv2.COLOR_RGB2BGR))
            except Exception as e:
                # å‡ºé”™æ—¶ä¿å­˜åŸå¸§ï¼ˆé¿å…ä¸­æ–­ï¼‰
                cv2.imwrite(frame_save_path, frame)
                print(f"âš ï¸  å¤„ç†å¸§ {frame_idx} å‡ºé”™ï¼š{str(e)}")
            
            frame_idx += 1
        
        cap.release()
        # ä¿å­˜å…ƒæ•°æ®ï¼ˆå‰ç«¯ç”¨äºåŒæ­¥ï¼‰
        metadata = {"fps": float(fps), "delay_frames": delay_frames, "total_frames": frame_idx}
        with open(os.path.join(output_dir, "metadata.json"), "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2)
        print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼š{output_dir}ï¼ˆå…±{frame_idx}å¸§ï¼‰")

# -------------------------- 4. æ–‡ä»¶å¤¹ç›‘æ§ä¸ä»»åŠ¡è°ƒåº¦ --------------------------
class WavMonitor:
    def __init__(self, processor: MuseTalkProcessor):
        self.processor = processor
        self.file_queue = queue.Queue()
        self.processing_log = load_processing_log()
        self.processed_files = set(self.processing_log.keys())

    def start_monitor(self) -> None:
        """å¯åŠ¨WAVæ–‡ä»¶å¤¹ç›‘æ§çº¿ç¨‹"""
        threading.Thread(target=self._monitor_loop, daemon=True).start()
        print("ğŸ” WAVæ–‡ä»¶å¤¹ç›‘æ§å·²å¯åŠ¨ï¼ˆæ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡ï¼‰")

    def _monitor_loop(self) -> None:
        """ç›‘æ§å¾ªç¯ï¼šå‘ç°æ–°WAVæ–‡ä»¶åˆ™åŠ å…¥é˜Ÿåˆ—"""
        while True:
            try:
                # éå†ç›‘æ§ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶
                for filename in os.listdir(CONFIG["WAV_MONITOR_DIR"]):
                    if not filename.lower().endswith(".wav"):
                        continue  # åªå¤„ç†WAVæ–‡ä»¶
                    if filename in self.processed_files:
                        continue  # è·³è¿‡å·²å¤„ç†çš„æ–‡ä»¶
                    
                    wav_src_path = os.path.join(CONFIG["WAV_MONITOR_DIR"], filename)
                    if not check_file_ready(wav_src_path):
                        continue  # è·³è¿‡æœªå®Œå…¨å†™å…¥çš„æ–‡ä»¶
                    
                    # ç”Ÿæˆå”¯ä¸€IDï¼ˆé¿å…æ–‡ä»¶åé‡å¤ï¼‰
                    base_name = os.path.splitext(filename)[0]
                    unique_id = f"{base_name}_{uuid.uuid4().hex[:8]}"
                    wav_dst_path = os.path.join(CONFIG["PROCESSING_TMP_DIR"], f"{unique_id}.wav")
                    
                    # ç§»åŠ¨æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
                    os.rename(wav_src_path, wav_dst_path)
                    
                    # è®°å½•æ—¥å¿—
                    self.processing_log[filename] = {
                        "status": "processing",
                        "start_time": datetime.now().isoformat(),
                        "unique_id": unique_id,
                        "output_dir": os.path.join(CONFIG["OUTPUT_FRAME_DIR"], unique_id)
                    }
                    save_processing_log(self.processing_log)
                    
                    # åŠ å…¥å¤„ç†é˜Ÿåˆ—
                    self.file_queue.put((wav_dst_path, filename, unique_id))
                    self.processed_files.add(filename)
                    print(f"ğŸ“¥ å‘ç°æ–°WAVæ–‡ä»¶ï¼š{filename}ï¼ˆå”¯ä¸€IDï¼š{unique_id}ï¼‰")
                
                time.sleep(0.5)  # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                print(f"âš ï¸  ç›‘æ§çº¿ç¨‹å‡ºé”™ï¼š{str(e)}")
                time.sleep(2)

    def start_workers(self) -> None:
        """å¯åŠ¨å¤„ç†çº¿ç¨‹æ± """
        for _ in range(CONFIG["NUM_WORKERS"]):
            threading.Thread(target=self._worker_loop, daemon=True).start()
        print(f"ğŸš€ å¯åŠ¨{CONFIG['NUM_WORKERS']}ä¸ªå¤„ç†çº¿ç¨‹")

    def _worker_loop(self) -> None:
        """å¤„ç†é˜Ÿåˆ—ä¸­çš„WAVæ–‡ä»¶"""
        while True:
            try:
                wav_path, original_filename, unique_id = self.file_queue.get()
                output_dir = os.path.join(CONFIG["OUTPUT_FRAME_DIR"], unique_id)
                os.makedirs(output_dir, exist_ok=True)
                
                # è°ƒç”¨MuseTalkå¤„ç†
                self.processor.process_video_frame(
                    video_path=CONFIG["VIDEO_PATH"],
                    audio_path=wav_path,
                    output_dir=output_dir
                )
                
                # æ›´æ–°æ—¥å¿—ä¸ºâ€œå®Œæˆâ€
                self.processing_log[original_filename]["status"] = "completed"
                self.processing_log[original_filename]["end_time"] = datetime.now().isoformat()
                save_processing_log(self.processing_log)
                print(f"âœ… WAVæ–‡ä»¶å¤„ç†å®Œæˆï¼š{original_filename}")
                
            except Exception as e:
                # æ›´æ–°æ—¥å¿—ä¸ºâ€œå¤±è´¥â€
                if original_filename in self.processing_log:
                    self.processing_log[original_filename]["status"] = "failed"
                    self.processing_log[original_filename]["error"] = str(e)[:500]
                    self.processing_log[original_filename]["end_time"] = datetime.now().isoformat()
                    save_processing_log(self.processing_log)
                print(f"âŒ å¤„ç†WAVæ–‡ä»¶ {original_filename} å‡ºé”™ï¼š{str(e)}")
            
            finally:
                self.file_queue.task_done()

# -------------------------- 5. å‰ç«¯æ’­æ”¾é¡µé¢ç”Ÿæˆï¼ˆè‡ªåŠ¨ç”ŸæˆHTMLï¼‰ --------------------------
def generate_frontend_html() -> None:
    """ç”Ÿæˆå‰ç«¯æ’­æ”¾é¡µé¢ï¼ˆç”¨äºæŸ¥çœ‹åŸè§†é¢‘+å˜´å½¢åŒæ­¥æ•ˆæœï¼‰"""
    html_content = '''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <title>MuseTalk å˜´å½¢åŒæ­¥æ’­æ”¾</title>
    <style>
        .container { display: flex; gap: 20px; margin: 20px; }
        .video-container { flex: 1; }
        #syncCanvas { border: 1px solid #ccc; }
        #status { margin-top: 10px; color: #666; }
    </style>
</head>
<body>
    <div class="container">
        <div class="video-container">
            <h3>åŸè§†é¢‘</h3>
            <video id="originalVideo" width="640" controls autoplay loop>
                <source src="original.mp4" type="video/mp4">
                æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ’­æ”¾
            </video>
        </div>
        <div class="video-container">
            <h3>å˜´å½¢åŒæ­¥è§†é¢‘</h3>
            <canvas id="syncCanvas" width="640" height="360"></canvas>
            <div id="status">ç­‰å¾…WAVæ–‡ä»¶å¤„ç†...</div>
        </div>
    </div>

    <script>
        // é…ç½®ï¼ˆéœ€ä¸åç«¯ä¸€è‡´ï¼‰
        const OUTPUT_FRAME_DIR = "./output_frames";
        const LOG_FILE = "processing_log.json";
        
        // DOMå…ƒç´ 
        const originalVideo = document.getElementById("originalVideo");
        const syncCanvas = document.getElementById("syncCanvas");
        const ctx = syncCanvas.getContext("2d");
        const statusElem = document.getElementById("status");
        
        // çŠ¶æ€å˜é‡
        let currentTask = null;  // å½“å‰å¤„ç†ä¸­çš„ä»»åŠ¡ï¼ˆå«unique_idå’Œmetadataï¼‰
        let frameIndex = 0;      // å½“å‰è¦æ¸²æŸ“çš„å¸§ç´¢å¼•
        let renderInterval = null;  // æ¸²æŸ“å®šæ—¶å™¨
        
        // 1. è½®è¯¢æ—¥å¿—ï¼Œè·å–æœ€æ–°å¤„ç†ä»»åŠ¡
        async function checkLatestTask() {
            try {
                const response = await fetch(LOG_FILE + "?t=" + Date.now()); // é¿å…ç¼“å­˜
                if (!response.ok) throw new Error("æ—¥å¿—è·å–å¤±è´¥");
                const log = await response.json();
                
                // æ‰¾åˆ°æœ€æ–°çš„â€œå¤„ç†ä¸­â€æˆ–â€œå·²å®Œæˆâ€ä»»åŠ¡
                let latestTask = null;
                for (const [filename, info] of Object.entries(log)) {
                    if (info.status === "processing" || info.status === "completed") {
                        latestTask = info;
                    }
                }
                
                if (latestTask && latestTask.unique_id !== currentTask?.unique_id) {
                    currentTask = latestTask;
                    statusElem.textContent = `å½“å‰ä»»åŠ¡ï¼š${latestTask.status === "processing" ? "å¤„ç†ä¸­" : "å·²å®Œæˆ"}ï¼ˆIDï¼š${latestTask.unique_id}ï¼‰`;
                    
                    // å¦‚æœä»»åŠ¡å·²å®Œæˆï¼ŒåŠ è½½å…ƒæ•°æ®å¹¶å¼€å§‹æ¸²æŸ“
                    if (latestTask.status === "completed") {
                        await loadMetadata(latestTask.output_dir);
                    }
                }
            } catch (e) {
                statusElem.textContent = `çŠ¶æ€æŸ¥è¯¢å‡ºé”™ï¼š${e.message}`;
            }
            setTimeout(checkLatestTask, 1000); // æ¯ç§’æŸ¥è¯¢ä¸€æ¬¡
        }
        
        // 2. åŠ è½½ä»»åŠ¡çš„å…ƒæ•°æ®ï¼ˆFPSã€å»¶è¿Ÿç­‰ï¼‰
        async function loadMetadata(outputDir) {
            try {
                const response = await fetch(`${outputDir}/metadata.json?t=` + Date.now());
                if (!response.ok) throw new Error("å…ƒæ•°æ®è·å–å¤±è´¥");
                const metadata = await response.json();
                
                // åœæ­¢ä¹‹å‰çš„æ¸²æŸ“
                if (renderInterval) clearInterval(renderInterval);
                
                // æŒ‰è§†é¢‘FPSè®¾ç½®æ¸²æŸ“é—´éš”
                const frameDelay = 1000 / metadata.fps; // æ¯å¸§çš„æ¯«ç§’æ•°
                frameIndex = 0;
                
                // å¯åŠ¨æ¸²æŸ“å¾ªç¯
                renderInterval = setInterval(() => {
                    if (!originalVideo.paused) {
                        renderFrame(outputDir, frameIndex);
                        frameIndex++;
                    }
                }, frameDelay);
            } catch (e) {
                statusElem.textContent = `å…ƒæ•°æ®åŠ è½½å‡ºé”™ï¼š${e.message}`;
            }
        }
        
        // 3. æ¸²æŸ“å•å¸§ï¼ˆä»åç«¯åŠ è½½ç”Ÿæˆçš„å¸§å¹¶ç»˜åˆ¶ï¼‰
        async function renderFrame(outputDir, index) {
            const framePath = `${outputDir}/frame_${index.toString().padStart(6, "0")}.jpg`;
            try {
                const img = new Image();
                img.src = framePath + "?t=" + Date.now(); // é¿å…ç¼“å­˜
                img.onload = () => {
                    ctx.drawImage(img, 0, 0, syncCanvas.width, syncCanvas.height);
                };
                img.onerror = () => {
                    // å¸§æœªç”Ÿæˆæ—¶ï¼Œç»˜åˆ¶åŸè§†é¢‘å½“å‰å¸§
                    ctx.drawImage(originalVideo, 0, 0, syncCanvas.width, syncCanvas.height);
                };
            } catch (e) {
                ctx.drawImage(originalVideo, 0, 0, syncCanvas.width, syncCanvas.height);
            }
        }
        
        // åˆå§‹åŒ–ï¼šå¯åŠ¨ä»»åŠ¡æŸ¥è¯¢
        checkLatestTask();
    </script>
</body>
</html>
'''
    # ä¿å­˜HTMLæ–‡ä»¶
    with open("musetalk_player.html", "w", encoding="utf-8") as f:
        f.write(html_content)
    print("âœ… å‰ç«¯æ’­æ”¾é¡µé¢å·²ç”Ÿæˆï¼šmusetalk_player.html")

# -------------------------- 6. ä¸»è¿è¡Œå…¥å£ --------------------------
if __name__ == "__main__":
    # 1. åˆå§‹åŒ–ç›®å½•
    init_dirs()
    
    # 2. ç”Ÿæˆå‰ç«¯æ’­æ”¾é¡µé¢
    generate_frontend_html()
    
    # 3. åˆå§‹åŒ–MuseTalkå¤„ç†å™¨
    processor = MuseTalkProcessor()
    
    # 4. åˆå§‹åŒ–ç›‘æ§å™¨å¹¶å¯åŠ¨
    monitor = WavMonitor(processor)
    monitor.start_monitor()
    monitor.start_workers()
    
    # 5. ä¿æŒä¸»ç¨‹åºè¿è¡Œ
    print("\nğŸ‰ ç³»ç»Ÿå·²å…¨éƒ¨å¯åŠ¨ï¼æ“ä½œæŒ‡å¼•ï¼š")
    print(f"1. å°†WAVæ–‡ä»¶æ”¾å…¥ç›‘æ§ç›®å½•ï¼š{CONFIG['WAV_MONITOR_DIR']}")
    print("2. æ‰“å¼€å‰ç«¯é¡µé¢æŸ¥çœ‹æ•ˆæœï¼šmusetalk_player.html")
    print("3. å¤„ç†æ—¥å¿—æŸ¥çœ‹ï¼šprocessing_log.json")
    print("\næŒ‰ Ctrl+C é€€å‡ºç³»ç»Ÿ...")
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        save_processing_log(monitor.processing_log)
        print("\nğŸ‘‹ ç³»ç»Ÿé€€å‡ºï¼Œæ—¥å¿—å·²ä¿å­˜")
        sys.exit(0)